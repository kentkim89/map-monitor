#!/usr/bin/env python3
"""
ë„¤ì´ë²„ ì‡¼í•‘ MAP ê°€ê²© ëª¨ë‹ˆí„°ë§ ìŠ¤í¬ë¦½íŠ¸
ì¿ íŒ¡ ë¡œì¼“í”„ë ˆì‹œ MAP ì •ì±… ìœ„ë°˜ íŒë§¤ì²˜ ìë™ ê°ì§€ ì‹œìŠ¤í…œ
"""

import json
import time
import random
import logging
import requests
from datetime import datetime
from typing import List, Dict, Optional
from dataclasses import dataclass, asdict
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.common.exceptions import TimeoutException, NoSuchElementException
import re
from urllib.parse import quote

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('map_monitor.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


@dataclass
class Product:
    """ì œí’ˆ ì •ë³´ í´ë˜ìŠ¤"""
    brand: str
    name: str
    map_price: int
    search_keyword: str


@dataclass
class Violation:
    """MAP ìœ„ë°˜ ì •ë³´ í´ë˜ìŠ¤"""
    ë¸Œëœë“œ: str
    ì œí’ˆëª…: str
    ì¿ íŒ¡_MAP: int
    ìœ„ë°˜_ì—…ì²´ëª…: str
    ìœ„ë°˜_ê°€ê²©: int
    ìœ„ë°˜_URL: str
    ë°œê²¬_ì‹œê°„: str


class Config:
    """ì„¤ì • ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, config_path: str = 'config.json'):
        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = json.load(f)
    
    @property
    def products(self) -> List[Product]:
        """ì œí’ˆ ëª©ë¡ ë°˜í™˜"""
        products = []
        for brand_data in self.config['products']:
            brand = brand_data['brand']
            for product in brand_data['items']:
                products.append(Product(
                    brand=brand,
                    name=product['name'],
                    map_price=product['map_price'],
                    search_keyword=product.get('search_keyword', product['name'])
                ))
        return products
    
    @property
    def n8n_webhook_url(self) -> str:
        return self.config['n8n']['webhook_url']
    
    @property
    def crawler_delay(self) -> tuple:
        delay = self.config['crawler']['delay_range']
        return (delay['min'], delay['max'])
    
    @property
    def user_agent(self) -> str:
        return self.config['crawler']['user_agent']


class NaverShoppingCrawler:
    """ë„¤ì´ë²„ ì‡¼í•‘ í¬ë¡¤ëŸ¬ í´ë˜ìŠ¤"""
    
    def __init__(self, config: Config):
        self.config = config
        self.driver = None
        self.violations = []
        
    def setup_driver(self):
        """Selenium ë“œë¼ì´ë²„ ì„¤ì •"""
        options = Options()
        options.add_argument(f'user-agent={self.config.user_agent}')
        options.add_argument('--disable-blink-features=AutomationControlled')
        options.add_experimental_option("excludeSwitches", ["enable-automation"])
        options.add_experimental_option('useAutomationExtension', False)
        # í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œ ì˜µì…˜ (í•„ìš”ì‹œ ì£¼ì„ í•´ì œ)
        # options.add_argument('--headless')
        options.add_argument('--no-sandbox')
        options.add_argument('--disable-dev-shm-usage')
        
        self.driver = webdriver.Chrome(options=options)
        self.driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
        
    def close_driver(self):
        """ë“œë¼ì´ë²„ ì¢…ë£Œ"""
        if self.driver:
            self.driver.quit()
            
    def check_captcha(self) -> bool:
        """ìº¡ì±  ì²´í¬"""
        try:
            # ë„¤ì´ë²„ ìº¡ì±  ìš”ì†Œ í™•ì¸
            captcha_elements = self.driver.find_elements(By.CLASS_NAME, 'captcha')
            if captcha_elements:
                logger.warning("âš ï¸ ìº¡ì±  ê°ì§€! í¬ë¡¤ë§ ì¤‘ë‹¨")
                return True
                
            # reCAPTCHA iframe í™•ì¸
            recaptcha = self.driver.find_elements(By.XPATH, "//iframe[@title='reCAPTCHA']")
            if recaptcha:
                logger.warning("âš ï¸ reCAPTCHA ê°ì§€! í¬ë¡¤ë§ ì¤‘ë‹¨")
                return True
                
        except Exception as e:
            logger.debug(f"ìº¡ì±  ì²´í¬ ì¤‘ ì˜¤ë¥˜: {e}")
            
        return False
    
    def random_delay(self):
        """ëœë¤ ì§€ì—° ì‹œê°„ ì ìš©"""
        min_delay, max_delay = self.config.crawler_delay
        delay = random.uniform(min_delay, max_delay)
        logger.debug(f"ëŒ€ê¸° ì‹œê°„: {delay:.2f}ì´ˆ")
        time.sleep(delay)
        
    def extract_price(self, price_text: str) -> Optional[int]:
        """ê°€ê²© í…ìŠ¤íŠ¸ì—ì„œ ìˆ«ì ì¶”ì¶œ"""
        try:
            # ìˆ«ìë§Œ ì¶”ì¶œ
            price = re.sub(r'[^\d]', '', price_text)
            return int(price) if price else None
        except:
            return None
            
    def crawl_product(self, product: Product) -> List[Violation]:
        """ê°œë³„ ì œí’ˆ í¬ë¡¤ë§"""
        violations = []
        
        try:
            # ë„¤ì´ë²„ ì‡¼í•‘ ê²€ìƒ‰ URL
            search_url = f"https://search.shopping.naver.com/search/all?query={quote(product.search_keyword)}"
            logger.info(f"ğŸ” ê²€ìƒ‰ ì¤‘: {product.name} ({product.brand})")
            
            self.driver.get(search_url)
            self.random_delay()
            
            # ìº¡ì±  ì²´í¬
            if self.check_captcha():
                raise Exception("ìº¡ì±  ê°ì§€ë¨")
            
            # ê²€ìƒ‰ ê²°ê³¼ ëŒ€ê¸°
            wait = WebDriverWait(self.driver, 10)
            wait.until(EC.presence_of_element_located((By.CLASS_NAME, "basicList_item__0T9JD")))
            
            # ìŠ¤í¬ë¡¤í•˜ì—¬ ë” ë§ì€ ìƒí’ˆ ë¡œë“œ
            for _ in range(3):
                self.driver.execute_script("window.scrollBy(0, 1000)")
                time.sleep(1)
            
            # ìƒí’ˆ ëª©ë¡ í¬ë¡¤ë§
            items = self.driver.find_elements(By.CLASS_NAME, "basicList_item__0T9JD")
            
            for item in items:
                try:
                    # ë¸Œëœë“œ í•„í„°ë§ (ê³ ë˜ë¯¸ ë˜ëŠ” ì„¤ë˜ë‹´ ì œí’ˆë§Œ)
                    title_elem = item.find_element(By.CLASS_NAME, "basicList_title__VfX3c")
                    title = title_elem.text
                    
                    if product.brand not in title:
                        continue
                    
                    # íŒë§¤ì²˜ ì •ë³´
                    try:
                        mall_elem = item.find_element(By.CLASS_NAME, "basicList_mall__BC5Xu")
                        mall_name = mall_elem.text
                    except:
                        mall_name = "ì•Œ ìˆ˜ ì—†ìŒ"
                    
                    # ê°€ê²© ì •ë³´
                    try:
                        price_elem = item.find_element(By.CLASS_NAME, "price_num__S2p_v")
                        price = self.extract_price(price_elem.text)
                    except:
                        continue
                    
                    # URL ì •ë³´
                    try:
                        link_elem = item.find_element(By.CLASS_NAME, "basicList_link__JLQJf")
                        product_url = link_elem.get_attribute('href')
                    except:
                        product_url = ""
                    
                    # MAP ìœ„ë°˜ ì²´í¬
                    if price and price < product.map_price:
                        violation = Violation(
                            ë¸Œëœë“œ=product.brand,
                            ì œí’ˆëª…=product.name,
                            ì¿ íŒ¡_MAP=product.map_price,
                            ìœ„ë°˜_ì—…ì²´ëª…=mall_name,
                            ìœ„ë°˜_ê°€ê²©=price,
                            ìœ„ë°˜_URL=product_url,
                            ë°œê²¬_ì‹œê°„=datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                        )
                        violations.append(violation)
                        logger.warning(f"âš ï¸ MAP ìœ„ë°˜ ë°œê²¬: {mall_name} - {price:,}ì› (MAP: {product.map_price:,}ì›)")
                    
                except Exception as e:
                    logger.debug(f"ì•„ì´í…œ íŒŒì‹± ì˜¤ë¥˜: {e}")
                    continue
                    
        except TimeoutException:
            logger.error(f"âŒ íƒ€ì„ì•„ì›ƒ: {product.name} ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        except Exception as e:
            logger.error(f"âŒ í¬ë¡¤ë§ ì˜¤ë¥˜ ({product.name}): {e}")
            
        return violations
    
    def crawl_all_products(self) -> List[Violation]:
        """ëª¨ë“  ì œí’ˆ í¬ë¡¤ë§"""
        all_violations = []
        
        try:
            self.setup_driver()
            
            for i, product in enumerate(self.config.products):
                logger.info(f"ì§„í–‰ ìƒí™©: {i+1}/{len(self.config.products)}")
                
                violations = self.crawl_product(product)
                all_violations.extend(violations)
                
                # ë§ˆì§€ë§‰ ì œí’ˆì´ ì•„ë‹ˆë©´ ì¶”ê°€ ëŒ€ê¸°
                if i < len(self.config.products) - 1:
                    self.random_delay()
                    
        finally:
            self.close_driver()
            
        return all_violations


class N8NIntegration:
    """n8n í†µí•© í´ë˜ìŠ¤"""
    
    def __init__(self, webhook_url: str):
        self.webhook_url = webhook_url
        
    def send_violations(self, violations: List[Violation]) -> bool:
        """ìœ„ë°˜ ë°ì´í„°ë¥¼ n8nìœ¼ë¡œ ì „ì†¡"""
        if not violations:
            logger.info("âœ… MAP ìœ„ë°˜ ì‚¬í•­ ì—†ìŒ")
            return True
            
        try:
            # Violation ê°ì²´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
            data = [asdict(v) for v in violations]
            
            # n8n Webhookìœ¼ë¡œ ì „ì†¡
            response = requests.post(
                self.webhook_url,
                json=data,
                headers={'Content-Type': 'application/json'}
            )
            
            if response.status_code == 200:
                logger.info(f"âœ… n8nìœ¼ë¡œ {len(violations)}ê±´ì˜ ìœ„ë°˜ ë°ì´í„° ì „ì†¡ ì™„ë£Œ")
                return True
            else:
                logger.error(f"âŒ n8n ì „ì†¡ ì‹¤íŒ¨: {response.status_code}")
                return False
                
        except Exception as e:
            logger.error(f"âŒ n8n ì „ì†¡ ì˜¤ë¥˜: {e}")
            return False


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    try:
        # ì„¤ì • ë¡œë“œ
        config = Config('config.json')
        logger.info("ğŸš€ MAP ê°€ê²© ëª¨ë‹ˆí„°ë§ ì‹œì‘")
        
        # í¬ë¡¤ë§ ì‹¤í–‰
        crawler = NaverShoppingCrawler(config)
        violations = crawler.crawl_all_products()
        
        # ê²°ê³¼ ì¶œë ¥
        if violations:
            logger.info(f"âš ï¸ ì´ {len(violations)}ê±´ì˜ MAP ìœ„ë°˜ ë°œê²¬")
            
            # JSON ì¶œë ¥ (stdout)
            violations_json = json.dumps(
                [asdict(v) for v in violations],
                ensure_ascii=False,
                indent=2
            )
            print(violations_json)
            
            # n8nìœ¼ë¡œ ì „ì†¡
            if config.n8n_webhook_url:
                n8n = N8NIntegration(config.n8n_webhook_url)
                n8n.send_violations(violations)
                
            # íŒŒì¼ë¡œ ì €ì¥
            with open('violations.json', 'w', encoding='utf-8') as f:
                f.write(violations_json)
                
        else:
            logger.info("âœ… MAP ìœ„ë°˜ ì‚¬í•­ ì—†ìŒ")
            print("[]")  # ë¹ˆ JSON ë°°ì—´ ì¶œë ¥
            
    except FileNotFoundError:
        logger.error("âŒ config.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    except Exception as e:
        logger.error(f"âŒ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        raise


if __name__ == "__main__":
    main()
